---
layout:     post
title:      DX12笔记 - 龙书记录
subtitle:   关于龙书里面的部分细节的记录
date:       2021-09-30
author:     BY 
header-img: 
catalog: true
tags:
    - DirectX12
---

# 前言

之前有看过LearnOpenGL，虽然说和DX12差别很大吧，但大体思路还是挺接近的。

这个笔记只记录了觉得自己觉得很有趣且需要留意的细节，所以并不是把每个章节进行一个总结。

# 第四章 - d3d初始化
## Com
控制DX12的一个接口，不能new但是可以通过函数去调用指针

## Depth buffer

DX12里面的深度为0~1， 0是最近，1是最远
使用深度缓存后，物体绘制顺序会变得不重要（因为可以用深度计算各自像素）

流程： 挨个绘制【所有】物体，并且每次绘制时更新缓存

纹理格式：一般32/24位给深度，可以留8位给模板缓冲stencil buffer

##资源与描述符

GPU想要对资源进行读写，就需要将该资源先绑定的渲染管线上。GPU在使用资源的时候大致需要知道两件事：

    要使用的是哪个资源？该资源充当什么角色？

资源描述符主要解决上述两件事。通过资源描述符引用要使用的资源很好理解。主要是资源描述符还需要解释资源充当的角色。因此我们可以把资源描述符分类，其中常用的有：

    CBV/SRV/UAV 常量缓冲区视图（constant buffer view）/ 着色器资源视图（shader resource view）/ 无序访问视图（unordered access view）
    
    采样器（sampler）用于纹理贴图
    
    RTV 渲染目标视图（render target view）
    
    DSV 深度/模板视图（depth/stencil view）

描述符堆表示特定类型描述符的一块内存。


## SSAA/MSAA

4x SSAA 需要花四倍的缓存去储存一个四倍的画面，然后再通过interp的方式形成最后的图片， 对每个像素都要进行着色计算

4x MSAA 也需要四倍的缓存，但只需要处理中心点在三角形内的像素。如果像素中心在三角形内，那么把像素分成4个， 然后根据多少中心点在三角形内外来对中心的颜色进行interp

## CPU GPU 同步

DX12整体流程是由cpu把指令传到队列里给GPU，但如果指令需要引用的资源在执行前被CPU改了，会出现问题， 所以需要同步

DX12同步使用的是fencing，就是给指令队列打上一个数字标签，在需要等待的地方调用flushing；flushing会把fence的数字提高一，然后等待之前的所有队列完成。

## 资源读写

为了让资源读写不冲突：

- 读取用资源状态为着色器资源
- 写入用资源状态为渲染目标

转换使用resource barrier，可以把需要读的数据的状态变成着色器资源这样。

## CmdList 和CmdQueue

CmdList 是在cpu上面储存的命令，会传递到gpu上的CmdQueue

## 代码初始化流程

1. 建立 com ptr
2. 设定一个目标资源，例如D3D12_DESCRIPTOR_HEAP_DESC，并填写参数
3. 此时资源并没有存入d3dDevice里，只是在缓存中有定义参数
4. 调用ThrowIfFailed(d3dDevice->createxxx) 把定义好的资源格式放到d3dDevice里，然后返回ptr到com ptr里



# 第六章 - 绘制几何体

## 顶点缓冲

把数据提交给vertex buffer的函数会先提交给一个中介区，叫upload buffer, 这是因为我们没办法直接把对应格式的提交到vertex buffer，所以先把原始数据搞过去，再按照格式赋值到vb

## 关于使用常量

1. 建立cbv的描述符到堆上面, D3D12_DESCRIPTOR_HEAP_DESC
2. 建立实际常量数据到缓冲区，这里只要map出UploadBuffer就可以通过memcpy在cpu端直接的改变常量数据
3. 建立根签名，把cbv绑定到一个寄存器里面，比如box里是绑定到b0

## Draw

在draw的时候会通过cmdlist把之前所有绑定好的数值进行一个执行，让数值真正的应用在队列/流水线中。Vertex buffer的不同槽也是在这时候才决定的

## 作业

### 第二题：使用两个顶点缓冲区传递Pos和Color

两个思路，都可以达成效果

1. 改变MeshGeometry,在里面添加ColorBuffer的存储
2. 使用一个额外的MeshGeometry存颜色

主要做法是分别存到不同的vertexbuffer里，然后在draw函数里
mCommandList->IASetVertexBuffers 分别往两个槽加数据

然后再BuildShadersAndInputLayout里改变shader输入格式



# 第七章 - 绘制几何体(续)

## 帧资源

把一个帧的cmdlist和常量都包装成一个帧的struct。这样在gpu处理第n帧的数据的时候，cpu可以预先处理n+1,n+2的数据。这样可以减少gpu的空闲时间。

使用fence可以让cpu追上gpu一圈的时候，进行一个等待。一般来说会希望cpu快于gpu，这样能充分利用gpu，然后剩余的cpu资源可以拿来做更多的游戏逻辑


## 矩阵行列

在dx12的内存中，矩阵是行主序的。但是在hlsl的内存是列主序，所有储存前要进行一个transpose

## 根签名2

根签名作用是在shader side描述heap。 有很多种，比如使用table来描述cbv的地址，或是直接传常量过去。

根常量绑定资源就不需要cbv，但是一个根常量只能绑定一个32位的常量值，空间消耗较大。


## 基本流程

### **Initialize**

**BuildRootSignature**

决定使用什么类型的cbv

**BuildShadersAndInputLayout**

绑定shader。 然后绑定每一组数据的不同变量在shader里的签名和偏移

**BuildShapeGeometry**

先把不同物体的vertex和index集做好，之后合并起来。
合并的时候记录每个物体自己的vertex和index在合集中的偏移和大小，这样可以合并的作为一组数据送给gpu

**BuildRenderItems**

在封装好的renderitem下把每个不同物体的顶点和索引和const buffer index进行储存

**BuildFrameResources**

把所有renderitem存到一个frameresource里【作用是让cpu可以提前计算下一帧的内容等待gpu】

同时在建立frameresource时也会建立uploadbuffer，也就是对cbv进行了map操作。可以直接通过memcpy把cpu的数据放到gpu上

**DescriptorHeaps**

把使用的cbv数量写入heap。这里因为有object的cb，也有pass的（比如摄像机相关的东西），所有还要把pass相对object的偏移写入

**BuildConstantBufferViews**

对每个object和pass添加一个cbv到gpu里。 过程中需要根据一个cb的大小去设定偏移储存在正确的位置。

**BuildPSO**

把前面所有的设定绑定到流水线上



# 第八章 - 光照

## 法线修正

当我们使用变换矩阵对一个物体进行拉伸的时候，原本的法线会对不上。这时候如果把变换矩阵套用在法线上面会出现错误的结果，但是如果我们把变换矩阵A，进行逆矩阵转置，也就是(A-1)T，就可以了

## 菲涅耳效应

作用于镜面光照(specular)：RF + (1-RF)(1-cos)^5, 这里rf是反射的百分比

之前学openGL用的布林冯笔记简单。感觉这里介整个渲染过程没必要提到pbr的东西...这个和微表面的roughness都是用于模拟pbr去进行的操作，可以代替bling phonn的高光达到更真实的效果。不过龙书在这里讲的个人并不是很满意。如果只是介绍光照怎么处理的，直接拿布林冯就可以了。 如果要提到pbr可以再更详细点介绍的，书讲的并不是很清楚的感觉。

## 添加CBV（作为material）

这里的话如果要使用3个register，那么就是建立3个uploadbuffer的指针。然后每个指针里面可以含有该类数据的好几个实际数据，根据索引来

1. 建立要放进的数据类和数据。并且给每个数据打上local的index(从0开始)
2. 建立描述堆的时候，形容总共需要存在多少个cbv，也就是帧资源*每个帧需要的cbv数量(每个物体的，每个material的，每个pass的)
3. BuildConstBufferView绑定。绑定的时候的heap index就是最后去呼叫这个资源时使用的index。这里因为物体的cbv是连续的，占用了帧数量*objectsize个索引，所有我们把material排在他们后面，pass的前面。要注意把heap index设定好。此时已经完美的把数据绑进去了
4. Update里在更新的时候，可以直接对该类和目标索引进行copydata
5. 使用的时候，先把需要的heap index提取出来，这里可以直接按照自己的排序方式手动计算。 拿出来后再绑定的自己想要绑定的register上面就行了

## 指定寄存器

每个寄存器里应该储存的“输入类型”是在BuildRootSignature时在描述符里建立的。接下来会建立一个根参数root parameter， 相当于外面再包一层指引。 根参数会把所有类型的寄存器t0t1b0b1这些放在一起，并且把索引对应到目标的寄存器上面。

比如我们需要创建一个纹理贴图t0,和两个常量b0b1，那么手续如下

1. 先给纹理建立一个描述符，类型srv,索引0
2. 给常量建立两个描述符，类型cbv,索引0和1
3. 建立大小为3的根参数，把他们一一放进去。
4. 在draw时，绑定索引0就是在指定t0, 索引1为b0, 索引2为b1



# 第九章 - 纹理贴图

## 添加材质流程

1. 从dds文件载入到一个包装好的含有resource / uploadbuffer的类
2. 在建立根签名的时候跟绑定cbv一样建立一个srv类型的描述符表(有几个槽位就建立几个描述符表)
3. 建立sampler的描述符表，如果使用static sampler可以跳过这一步，在建立根签名描述符的时候可以直接把static sampler作为参数放进去。
4. 建立一个srv描述符堆，n个槽位就在这个描述符堆的参数里填写n个descriptor
5. 创造shader resource view，把需要用到的所有贴图绑定到对应offset的srv上面，中间堆里的offset就是(1, mCbvSrvUavDescriptorSize)
6. 调用的时候绑定srv描述符堆的地址（步骤4里建立的），然后根据需要渲染的物体去选取他们使用的贴图在srv heap里面的位置

根参数指定槽位数量， srv描述符堆决定了gpu总共会使用多少个贴图，这两个不冲突。



# 第十章 - 混合

## Shader里面的define
在定义shader的时候，除了指定文件以外可以对第二个参数输入一个D3D_SHADER_MACRO，来调整shader内的MACRO值。之后可以绑定到对应的pso里这样可以对不同的物体采取不同的操作。

## Blending设置

在PSO的设置里有一个blendState参数。定义一个BLEND_DESC然后把他放进pso里面可以控制后来绘制的物体和之前的物体进行blending的模式。

可以准备很多不同的pso，然后在渲染不同物体的时候可以调用合适的pso。

可以把物体分成不同种类这样可以先渲染opaque的然后再透明的。

# 第十一章 - 模板
## 镜面反射
1. 设置好镜子位置，并且根据镜子位置把需要反射的物体复制且翻转到镜子后方（实则两个物体）
2. 先用普通pso渲染普通的物体
3. 渲染镜子: 使用OMSetStencilRef(1)把当前stencil参考值设置成1 (0~255), 并且在pso里把stencil test设置成永远通过，然后值是replace，颜色禁止写入。 这样在渲染镜子物体的时候会把镜子所包括的像素全部replace成我们指定好的1。 当然，这里还要进行深度测试防止镜子被挡住
4. 渲染反射物体： 这里不修改stencilref， 然后把镜子后的物体用reflect的pso进行渲染。这个pso的设定是值必须equal，也就是当前的StencilRef必须与缓存中指定像素的Stencil值相等，才会把像素渲染出来

大致的思路就是多拷贝一份镜像后的物体。然后把镜子写入模板缓存，照着缓存把物体渲染出来。 这里要注意的是被反射物体在进行转换矩阵后，三角形的法线会朝向内部，所以在pso里还要额外设定把三角形的顺序进行翻转。

## 绘制阴影
1. 给目标物体备份出一个用shadow material的备份
2. 使用阴影投影矩阵把shadow物体投影到目标变换(相当于渲染一个半透明物体)
3. 由于阴影实际上是个实物，所以半透明根据绘画顺序可能会叠加出一些噪音点(渲染了后侧半透明，再渲染前侧的半透明，这个三角形会更暗)，所以这里也要用到模板缓存
4. 模板测试的ref为0，条件为equal，通过后increment

# 第十二至十四章
## 跳过
计算着色器个人觉得有一点cuda的味道，现阶段理解一个大概就好了，之后在搓demo的时候再回访这部分的知识更合适。

# 第十五章 - 构建摄像机
## 动态索引
### 动态Structure Buffer
我们如果想一次性把所有的材质传入gpu，在一次渲染中把不同材质的物体渲染出来，我们可以用一个动态的upload buffer叫Structure Buffer。这个是通过srv/uav格式传入shader里的，然后我们可以动态的去修改里面的内容就像修改cbv一样。

为什么不用cbv？因为cbv没办法传入一个自定义struct的array。

### 多个贴图
多个贴图有不同的方式可以载入我们的shader
1. Texture2DArray: 占用一个寄存器，不过要求格式相同
2. Texture2D 多寄存器: 占用多个寄存器，不要求格式相同
3. Texutre2D[]: 同样会占用多个寄存器，不过相对来说索引起来更加方便，否则我们需要对每个不同寄存器的变量使用if else来进行调用。

# 第十六章 - 实例化和视锥体剔除
## 实例化与和批次
### 优势
1. 节省空间: 多个相同的物体(例如植被)享有相同的局部顶点坐标。如果我们把各自分开来渲染的话，那么为相同备份的物体我们会在内存里储存多份局部顶点等信息，这样有很多的内存开销。 如果可以使用实例化那么我们只需要一份这个顶点的拷贝
2. 节省时间: 传统的实例化他并不包含和批次(batch rendering)技术，并没有节省空间。但是在dx12里有把他们融合在一起，batch rendering就是通过一次绘制调用(draw call)来绘制多个物体。
### 传递参数
在进行实例化的时候大多物体都是有着不一样的世界坐标，并且很有可能也占用着不同的材质和贴图，所有我们在进行这种和批次的实例化的时候没有办法像之前一样针对每次draw call去更改这样的const值。

就像上一章的内容一样，cbv他并不能包含array，所有我们一样要通过structured buffer/ srv进行数据的传入。 srv的好处是首先这个array的大小并不受限制，也就是我们把根签名设置好后并不需要有固定的大小，针对不同的批次可以有不同的渲染。


## 视锥体剔除
### 简介
一般来说在我们的gpu管线里的裁剪阶段，对于视锥体外的三角形我们的硬件会直接把他们丢掉。但是丢掉之前我们确实也会对这些三角形进行draw call来传入gpu，这些都有一定的成本，所有为了减少这部分的开销，我们可以用cpu去计算视锥体剔除，这样可以不提交在视锥体外的物体。
### 思路
使用包围盒(AABB)或者包围球围绕场景里所有的物体，并且计算是否和视锥体相交。

### 视锥体表示
DX12内置了结构体BoundingFrustum结构如下
 1. XMFLOAT3 Origin
 2. XMFLOAT4 Orientation
 3. float RightSlope
 4. float LeftSlope
 5. float TopSlope
 6. float BottomSlope
 7. float Near, Far
slope可以给出上下左右四个平面在对应距离下的位置。 通过上面的几个参数可以得到视锥体所拥有的6个平面。

### 关于平面和相交
```
法线: n(a,b,c)

平面中的点: p0(x,y,z)

d = dot(-n, p)
```

平面可以写成 ax + by + cz + d = 0, 也就是 dot(n,p) + d = 0

### 平面和球
给出任意点p,我们可以计算dot(n (p - p0))，很直观的就是一个点离平面的最近直线距离。我们在计算平面和球的相交的时候可以使用这个公式，带入球体的正中心，算出球和平面的最短距离来判断球是否在视锥体中间。要注意的是视锥体的法线是朝内的。

### 平面和AABB
AABB有四个对角向量(算上正负为八)，找出和法线最相似的（值最大的）,对角的两个点为pq，我们可以直接算两个点是否在平面前/后来得出整个物体是否在平面的前后。

### DX12视锥体
DX12的视锥体可以直接通过projection的matrix对boundingFurstrum类进行直接的构造。 然后我们在针对所有物体的时候进行一个view space到local space的变换（所有相同物体的local space的AABB都一样，可以不用重复计算）。有frustum后直接针对所有物体设定好的bounds放contains函数，就可以得到说物体是不是在我的frustum里面，不需要手动去计算上面的理论

# 第十八章 - 立方体贴图
## 动态立方体贴图
### 反射和立方体贴图
我们在dx12里面可以直接去加载一个cube map来当作材质投影。我们在对带反射的材质(如镜子)等物体里反射背景的时候，也可以通过使用立方体贴图来描绘反射后的环境。这样做的优势是跑得很快也不需要进行任何的光线追踪，不过衍生出的问题就说没用办法对动态物体进行采样。

也就是说我们只能反射天空盒，或者一次性渲染完的场景，那么为了对场景进行更真实的反射，我们需要用到动态立方体贴图。也就是说我们会在每一帧在世界中心往周围的6个方向进行渲染，渲染到自定义的立方体贴图中供其他的反射材质使用。

### 渲染到立方体贴图
1. 由于我们需要把场景放到立方体贴图，那么我们就需要对应的RTV来储存渲染结果，和SRV提供给shader调用。那么我们需要去封装一个类来包含这些rtv
2. 为每个面建立一个摄像机
3. 为每个面建立一个常量缓冲(对应projection matrix啥的)
4. 调整渲染的目标的类型(resource barrier)。我们需要把我们整体的立方体的resource整体从generic read变成render target(从可读变成可写)
5. 对每次渲染(out of 6), 把render target设置成立方体对应的rtv渲染
6. 读取的时候再直接读取之前设置好的srv就行

### 解释
从头到尾就只有一份resource，也就是cubemap的resource。我们用描述符把resource写成了拥有6个rtv，那么我们就可以在同一个资源内写入6个rtv，但资源是不变的。

这个时候我们又定义了另一份描述符说这个资源是srv，那么我们就可以用cube map的形式去读之前写好的resource。

### 优化
上面的办法需要对场景进行6次渲染才能得到整个cubemap，这样的开销特别的大。实际上可以用过geometry shader来让一次的提交就能填满整个cubemap。

优化的方式是：
1. 比起使用6个rtv和6个描述符，这里只是用了一个rt描述符来形容一个大小为6的texture2Darray。(原本的做法是创造6个描述符。每个描述符也都是texture2darray，指向了第i个index，并且大小为1。这个做的原因是原本我们需要过6个pass，并且每个pass需要有办法去指定对应的rtv，所以要分成六份。这里的话只有一个pass,所以只需要建立一个描述符，且texture2Darray大小为6。)
2. 建立大小为6的cb来储存六个方向的摄像机情报
3. 建立大小为6的depthStencilView
4. 跑GS的时候，我们可以通过output.RTIndex来指定我们想要渲染到的RT的index number。这样的话针对每个三角形(triangle stream)，我们可以进行大小为6的循环把每个output放到每一个rt里面。
5. 也就是说，如果跑一次vs,在gs后会跑6次ps分别导入到各自rtv里面。

# 第十九章 - 法线贴图

## 法线贴图
### 前言
当我们需要实现一些比较特殊的效果的时候，基于几何体的法线没有办法达到理想的效果。那么我们就需要去通过一个贴图来储存我们需要用到的法线。

### 为什么要用切空间
https://blog.csdn.net/liran2019/article/details/106452266/

这个问题首先是要讲为什么法线贴图并不能直接存在于局部空间。实际上我们确实可以把法线贴图的点记录为局部空间，不过这样的泛用性会十分的糟糕。很显然我们可以写入一个法线向量，然后再根据物体整体的一个srt变换(主要是r)去进行方向的转变，但仔细想想，如果我要为一个球设置这样的法线贴图，那么所有法线都会是根据球来计算的，没有办法套用在其他的几何体上面。简单来说就是缺乏局部性，假设物体形变了也会失效。

我们想一想我们每个几何体能提供什么样的信息来达到局部性，首先几何体本身是能有几何体的法线的，也可以计算出切线。那么比起针对整个几何体去定制一个法线贴图，我们可以把几何内的每个三角形看作一个面，然后根据面的几何法线方向去定制我们的法线贴图所需要提供的信息，也就是TBN空间。

(物体局部空间为针对整个物体，而tbn空间是针对每个三角形为面的几何上的一个法线相对方向)

### TBN变换
TBN为Tangent, Bitangent, Normal,都是形容几何的向量而不是normal map的。 在我们进行对normal map的采样之前，会先把T和N通过世界变换矩阵放到合适的位置。 之后通过叉乘可以计算出TBN。

所以我们在进行normal map采样的时候已经确保了TBN是在正确的朝向。
```
(x y z) * (ttt bbb nnn) =  (xtbn, ytbn, ztbn) 这样
 ```


# 第二十章 - 阴影贴图
## 原理
从光源的角度进行一个正交投影，把物体转换到ndc空间来计算([-1,1])，然后把对应的深度值放到一个贴图里面。 之后我们在常规渲染的时候，我们把看见的每个像素通过和光源的正交变换，来得到在shadow map里面的索引。之后我们对比当前像素对光源的距离和索引内的距离，决定是否要渲染物体。

## Shadow Map 结构
shadow map的话我们可以包装成一个工具类，它跟18章的记录反射时用的方式特别相似，就是要自定义device, viewport, scissor rect这些。不过我们并不需要一个rtv，相对的在可写入的资源描述符我们只使用一个dsv就好了来记录深度。

这里的话在调用OMSetRenderTargets时我们把render target设定成null就好，因为深度会记录在dsv里面。

## 纹理映射
当我们在shadow pass中把深度存到纹理，我们要把ndc空间的物体[-1,1]投影到纹理坐标[0,1]上面。这里的话是非常简单的  x*0.5 + 0.5 就可以达到。

## 阴影走样
我们在通过光源是看一个平面的时候，一个很大的问题就是分辨率的不足。 比如说我们的光源用45度角去看一个平面，那么光源的阴影贴图内的一个像素，可能就是正常渲染贴图里面的两三个像素，而其中的一两个会被我们的shader认为是被挡住了。 这时候我们渲染出来的效果会有很多以为自己被挡住了的像素在平面上，会走样出很多条纹。

### 使用偏移解决阴影走样
这里我们可以在设置深度的时候，给深度上一个偏移，也就是记录的深度比实际深度还深。这样子我们在渲染平面的时候，无论怎么测量都不会有任何的遮挡问题。不过如果偏移值没有设定好，那么阴影可能会和实体分开，弄得不真实。

当然，dx12对此也有一定的支持。我们可以通过设定光栅器的SlopeScaledDepthBias，来让斜度更高(更容易被遮挡)的平面拥有更多的偏移。

### PCF(percentage closer filtering)
有的时候我们渲染时选中的像素并不能应对shadow map中的其中一个像素，可能会卡在shadow map的多个像素中间，这时候我们不能直接对深度进行filter，所以需要PCF。

PCF的做法就是选取阴影贴图上周围的4(或者9)个点，逐个计算深度是否挡住了我们要渲染的像素。如果挡住了就是0，没挡住就是1。拿最后的结果除以4(或者9)就能得到平均的阴影，也就是软阴影。

注：我们没有看深度的均值，而是看附近的像素平均有几个 挡住了我们的目标像素，来达到有灰度的阴影。

## 实际流程
1. 建立shadow map类，含有device等基本信息
2. 为shadow map 增加可读的srv和可写的dsv
3. 设置好光源的orthogonal变换矩阵
4. 渲染一次场景用shadow的shader。 shader所做的就是通过变换矩阵放到光源摄像机所看到的合适的位置。此时物体的深度(变换后的pos.z/pos.w)会被记录在[0,1]的范围内。记录的位置就是光源摄像机窗口对应ndc空间的位置
5. 渲染普通物体1: 通过转换矩阵把我们的像素面对光源的位置显示出来。 这里不能使用之前所用的ndc空间，我们需要把所有值规范化从ndc的[-1,1]到[0,1]，可以在cb里设置好对应的矩阵
6. 渲染普通物体2: 呼叫pcf函数。这里因为我们把ndc的位置直接转换到[0,1]，所以物体的pos.x,pos.y就是我们在阴影贴图对应的像素，所以可以直接对比深度。 这个时候带几个offset去把shadow map对应的像素的深度一起对比就能完成pcf。

要注意的是之前所说的偏移本身是在dx12的光栅器里面已经内置好的，不需要手动去操作。

## 部分细节（有重复）
### 怎么把depth写出来？
只需要简单的投影，然后我们的z值就会自动的从ndc变成[0,1]放在dsv里面
### 怎么在正式pass找到像素在阴影图对应的深度？
我们通过之前使用的光源投影就有ndc空间的了。 这时候再加一个从[-1,1]到[0,1]的变换矩阵就能找到在[0,1]空间的位置了。 这时候的xy就是阴影图对应的xy,z也就是深度。

# 第二十一章 - 环境光遮蔽
## 普通的AO
对每个三角形的中心往normal方向外进行随机光线投射，如果在一定范围内有碰撞，那么我们知道我们这个三角形有被遮挡，并且写入ao值里面。

开销过大,虽然对于静态的画面可以通过烘培一次性渲染到occlusion map，但我们在有动态场景的时候这个算法并不适用。

## SSAO流程
SSAO这里的话会多出三个pass给整个流程，一个是把normal和深度记录下来，另外两个是ssao(建立ssao图，模糊ssao图)
1. 建立一个SSAO的类储存一个3个resource(normal map, ssao, 模糊后ssao)，都要可读的srv和可写的rtv
2. 在ssao类把dsv的句柄绑定到原生的dsv里面。这里因为我们渲染normal图使用的dsv不会像shadow map那样和正常视角的遮挡冲突，所以可以直接用原生的dsv。 
所以这里只是把heap index指向原生的，没有新建任何resource
3. 由于ssao的建立需要不一样的cb/贴图输入格式，所以额外建一个root signature来为此服务
4. 先用normal的pso把数据储存到我们的normal map里面并且不清除dsv
5. 由于我们之前绑定过了t0 是normal map resource的位置， t1是原生dsv的位置，所以我们换ssao的pso渲染的时候可以直接使用这两个数据
6. 进行ssao的pso渲染的时候，我们把输入的vertex buffer, index layout, index buffer全都关闭，然后调用一个cmdList->DrawInstanced(6, 1, 0, 0);来传进去数字0~5。
我们可以通过传进去的vertex id，来指定已经写在hlsl里面的屏幕坐标[0,1]。
7. 在vs简单地把[0,1]坐标转换回ndc空间，同时保留纹理的索引
8. 接下来因为在ps是逐像素操作，我们可以针对每个像素通过normal map和depth map去进行ssao的计算，并且把结果写入我们之前设定好的ambient map
9. 之后还要再跑一个pass来对我们的ambient map进行模糊操作来达成最后的ssao图，这个跟上一个流程几乎差不多。
10. 在进行常规渲染的时候，我们可以在ps里通过ndc坐标对纹理坐标的转换来找到对应的ambient map值